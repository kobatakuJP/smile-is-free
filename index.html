<!DOCTYPE html>
<html>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# website: http://ogp.me/ns/websaite#">
    <meta property="og:url" content="https://kobatakujp.github.io/smile-is-free/" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="はい笑って～" />
    <meta property="og:description" content="Webカメラを使っていろんな表情をしましょう。表情がキまるとカメラマンがいただいてくれます。さあ、恥ずかしがらず。※難しいお題は「次のお題」を押してスキップしましょう。表情のヒントはこちらを参考に→https://justadudewhohacks.github.io/face-api.js/docs/index.html" />
    <meta property="og:image" content="https://kobatakujp.github.io/smile-is-free/img/cameko.png" />
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <title>はい 笑って～</title>
    <meta content="Webカメラを使っていろんな表情をしましょう。さあ、恥ずかしがらず。※一部難易度高い表情があるので、「次のお題」を押してスキップしましょう。" name="description" />
    <link rel="stylesheet" type="text/css" href="./css/index.css" />
    <style>
        #app {
            position: relative;
        }

        #app * {
            position: fixed;
        }
    </style>
</head>

<body>
    <div id="app">
        <video ref="video" width="400" height="400" @play="onPlay" @pause="onPause"></video>
        <canvas ref="canvas" width="400" height="400"></canvas>
        <div class="arrow_box" style="left: 200px; position: relative">
            <div style="position: absolute; top:50%;left:50%;transform:translateY(-50%) translateX(-50%);">
                {{cameraComment}}</div>
        </div>
        <img src="img/cameko.png" style="width: 200px; left: 300px; top: 100px;" />
        <div style="left: 350px; top: 300px;">
            <div v-for="p in points">
                <div style="background-color: white;">{{p}}点！</div>
            </div>
        </div>
        <button @click="next">次のお題</button>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/vue@2.6.10/dist/vue.min.js"></script>
    <script src="js/face-api.min.js"></script>
    <span style="position:fixed;bottom:0;right:0;">Powered by <a href="https://github.com/justadudewhohacks/face-api.js"
            target="_blank">face-api.js</a></span>

    <script>
        /** 表情リスト */
        const EXPRESSION_LIST = [
            { id: "angry", word: "怒って～" },
            { id: "disgusted", word: "うんざりして～" },
            { id: "fearful", word: "恐れて～" },
            { id: "happy", word: "笑って～" },
            { id: "neutral", word: "無表情で～" },
            { id: "sad", word: "悲しんで～" },
            { id: "surprised", word: "驚いて～" }
        ]
        new Vue({
            el: '#app',
            data: {
                MODEL_URI: './js/models',   // 顔認識モデルの場所
                currentWantExpressionID: EXPRESSION_LIST[3].id,
                word: EXPRESSION_LIST[3].word,
                intervalID: -1,
                points: []
            },
            computed: {
                video() { return this.$refs['video']; },
                canvas() { return this.$refs['canvas']; },
                cameraComment() { return `はい ${this.word}` }
            },
            watch: {
                cameraComment: function (v) {
                    document.title = v;
                }
            },
            methods: {
                onPlay() {
                    const video = this.video;
                    const canvas = this.canvas;
                    this.intervalID = setInterval(async () => {
                        // 参考URL https://blog.capilano-fw.com/?p=4063
                        // ウェブカメラの映像から顔データを取得
                        const detections = await faceapi.detectAllFaces(
                            this.video,
                            new faceapi.TinyFaceDetectorOptions()
                        )
                            .withFaceLandmarks()
                            .withFaceExpressions();
                        this.updatePoints(detections);
                        if (this.isOK(detections)) {
                            this.word = "いただきました！"
                            video.pause();
                        }
                        // 顔データをリサイズ
                        const resizedDetections = faceapi.resizeResults(detections, {
                            width: video.width,
                            height: video.height
                        });
                        // キャンバスに描画
                        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                        faceapi.draw.drawDetections(canvas, resizedDetections);
                        // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                        // faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
                    }, 500);
                },
                onPause() {
                    if (this.intervalID > -1) clearInterval(this.intervalID);
                },
                updateExpression() {
                    const next = EXPRESSION_LIST[Math.floor(Math.random() * EXPRESSION_LIST.length)];
                    this.currentWantExpressionID = next.id;
                    this.word = next.word;
                },
                /** 写っている全員が現在指定されている表情になっているか */
                isOK(detections) {
                    if (detections && detections[0]) {
                        return detections.filter(v => v.expressions[this.currentWantExpressionID] > 0.95).length === detections.length
                    }
                    return false;
                },
                updatePoints(detections) {
                    if (detections && detections[0]) {
                        this.points.splice(-this.points.length);
                        detections.map(v => this.points.push(Math.floor(v.expressions[this.currentWantExpressionID] * 100)))
                    }
                },
                next() {
                    this.updateExpression();
                    this.video.play();
                }
            },
            mounted() {
                // 顔モデルをロード
                Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(this.MODEL_URI),
                    faceapi.nets.faceLandmark68Net.loadFromUri(this.MODEL_URI),
                    faceapi.nets.faceExpressionNet.loadFromUri(this.MODEL_URI)
                ])
                    .then(() => {
                        // ウェブカメラへアクセス
                        navigator.mediaDevices.getUserMedia({ video: true })
                            .then((stream) => {
                                this.video.srcObject = stream;
                                this.video.play();
                            });
                    });
            }
        });
    </script>
</body>

</html>